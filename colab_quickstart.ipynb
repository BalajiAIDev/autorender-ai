{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ðŸš€ Autorender AI - Colab Quickstart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ðŸš€ AutoRender AI - Google Colab Quickstart\n",
    "\n",
    "This notebook sets up the **AutoRender AI microservice** on Google Colab with:\n",
    "- ðŸŽ¨ Background removal with edge refinement\n",
    "- ðŸŒŸ AI background generation using Stable Diffusion  \n",
    "- ðŸ” Object detection and smart cropping\n",
    "- ðŸ‘¤ Face detection and cropping\n",
    "- âš¡ GPU acceleration\n",
    "- ðŸŒ Public URL via ngrok tunnel\n",
    "\n",
    "**âš ï¸ Important:** Make sure to enable GPU runtime: `Runtime > Change runtime type > Hardware accelerator > GPU`\n",
    "\n",
    "---\n",
    "\n",
    "## ðŸ“‹ Step 1: Environment Setup & GPU Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import sys\n",
    "import os\n",
    "\n",
    "print(\"ðŸ–¥ï¸  System Information:\")\n",
    "print(f\"   Python: {sys.version.split()[0]}\")\n",
    "print(f\"   PyTorch: {torch.__version__}\")\n",
    "print(f\"   CUDA Available: {torch.cuda.is_available()}\")\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"   GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"   GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.1f} GB\")\n",
    "    print(f\"   CUDA Version: {torch.version.cuda}\")\n",
    "else:\n",
    "    print(\"   âš ï¸  No GPU detected. Enable GPU in Runtime > Change runtime type\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## ðŸ“¦ Step 2: Clone Repository & Install Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clone the AutoRender AI repository\n",
    "print(\"ðŸ“¥ Cloning AutoRender AI repository...\")\n",
    "!git clone https://github.com/BalajiAIDev/autorender-ai.git\n",
    "%cd autorender-ai\n",
    "\n",
    "print(\"âœ… Repository cloned successfully!\")\n",
    "print(\"\\nðŸ“¦ Installing system dependencies...\")\n",
    "\n",
    "# Install system dependencies\n",
    "!apt-get update -qq\n",
    "!apt-get install -y -qq libgl1-mesa-glx libglib2.0-0 libsm6 libxext6 libxrender-dev libgomp1\n",
    "\n",
    "print(\"âœ… System dependencies installed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"ðŸ“¦ Installing Python dependencies...\")\n",
    "\n",
    "# Install PyTorch with CUDA support first\n",
    "!pip install -q torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118\n",
    "\n",
    "# Install other dependencies from requirements.txt\n",
    "!pip install -r requirements.txt\n",
    "\n",
    "print(\"âœ… All Python dependencies installed!\")\n",
    "\n",
    "# Verify key imports\n",
    "print(\"\\nðŸ” Verifying key imports...\")\n",
    "try:\n",
    "    import flask\n",
    "    import rembg\n",
    "    import ultralytics\n",
    "    import diffusers\n",
    "    import pyngrok\n",
    "    print(\"âœ… All critical packages imported successfully!\")\n",
    "except ImportError as e:\n",
    "    print(f\"âŒ Import error: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## ðŸ”‘ Step 3: Setup Ngrok (Optional - for permanent URLs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional: Add your ngrok auth token for permanent URLs\n",
    "# Get your token from: https://dashboard.ngrok.com/get-started/your-authtoken\n",
    "\n",
    "NGROK_AUTH_TOKEN = \"\"  # Add your token here if you have one\n",
    "\n",
    "if NGROK_AUTH_TOKEN:\n",
    "    from pyngrok import ngrok\n",
    "    ngrok.set_auth_token(NGROK_AUTH_TOKEN)\n",
    "    print(\"ðŸ”‘ Ngrok auth token configured!\")\n",
    "else:\n",
    "    print(\"â„¹ï¸  No ngrok auth token provided. You'll get a temporary URL.\")\n",
    "    print(\"   To get a permanent URL, sign up at https://ngrok.com\")\n",
    "\n",
    "# Set environment for Colab\n",
    "import os\n",
    "os.environ['FLASK_ENV'] = 'colab'\n",
    "os.environ['ENABLE_NGROK'] = 'true'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## ðŸš€ Step 4: Start AutoRender AI Service"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import threading\n",
    "import time\n",
    "import subprocess\n",
    "\n",
    "print(\"ðŸš€ Starting AutoRender AI service...\")\n",
    "print(\"â³ This will take a moment to load AI models...\")\n",
    "\n",
    "# Start the Flask app with ngrok in background\n",
    "def start_app():\n",
    "    subprocess.run([\"python\", \"app.py\"], capture_output=False)\n",
    "\n",
    "# Start server in background thread\n",
    "server_thread = threading.Thread(target=start_app)\n",
    "server_thread.daemon = True\n",
    "server_thread.start()\n",
    "\n",
    "print(\"âœ… Server starting... Please wait for ngrok URL to appear above.\")\n",
    "print(\"ðŸ” Look for a line that shows: 'running on https://xxxxx.ngrok.io'\")\n",
    "\n",
    "# Wait for server to start\n",
    "time.sleep(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## ðŸ§ª Step 5: Test the Service"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "import time\n",
    "\n",
    "# Wait a bit more for full startup\n",
    "time.sleep(5)\n",
    "\n",
    "print(\"ðŸ” Testing the AutoRender AI service...\")\n",
    "\n",
    "# Test local health endpoint first\n",
    "try:\n",
    "    response = requests.get(\"http://localhost:5000/health\", timeout=10)\n",
    "    if response.status_code == 200:\n",
    "        print(\"âœ… Local health check passed!\")\n",
    "        print(json.dumps(response.json(), indent=2))\n",
    "    else:\n",
    "        print(f\"âŒ Local health check failed: {response.status_code}\")\n",
    "except Exception as e:\n",
    "    print(f\"âš ï¸  Local connection issue: {e}\")\n",
    "    print(\"Server might still be starting up...\")\n",
    "\n",
    "print(\"\\nðŸ“‹ Service Status:\")\n",
    "try:\n",
    "    response = requests.get(\"http://localhost:5000/status\", timeout=10)\n",
    "    if response.status_code == 200:\n",
    "        status = response.json()\n",
    "        print(f\"âœ… Service running with {len(status.get('endpoints', {}))} endpoint categories\")\n",
    "        print(f\"ðŸ¤– Models available: {list(status.get('models', {}).keys())}\")\n",
    "    else:\n",
    "        print(f\"âŒ Status check failed: {response.status_code}\")\n",
    "except Exception as e:\n",
    "    print(f\"âš ï¸  Status check issue: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## ðŸŽ¨ Step 6: Test Background Removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import base64\n",
    "from PIL import Image, ImageDraw\n",
    "from io import BytesIO\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print(\"ðŸ“· Creating test image for background removal...\")\n",
    "\n",
    "# Create a simple test image\n",
    "width, height = 400, 400\n",
    "image = Image.new('RGB', (width, height), 'white')\n",
    "draw = ImageDraw.Draw(image)\n",
    "\n",
    "# Draw a red circle\n",
    "center_x, center_y = width // 2, height // 2\n",
    "radius = 80\n",
    "draw.ellipse(\n",
    "    [center_x - radius, center_y - radius, center_x + radius, center_y + radius],\n",
    "    fill='red',\n",
    "    outline='darkred',\n",
    "    width=3\n",
    ")\n",
    "\n",
    "# Add some text\n",
    "try:\n",
    "    draw.text((center_x - 30, center_y - 10), \"TEST\", fill='white')\n",
    "except:\n",
    "    draw.text((center_x - 20, center_y - 5), \"AI\", fill='white')\n",
    "\n",
    "# Save test image\n",
    "image.save('test_image.jpg', 'JPEG')\n",
    "\n",
    "# Display the test image\n",
    "plt.figure(figsize=(6, 6))\n",
    "plt.imshow(image)\n",
    "plt.title(\"Original Test Image\")\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "\n",
    "print(\"âœ… Test image created successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"ðŸŽ¨ Testing background removal API...\")\n",
    "\n",
    "try:\n",
    "    # Test background removal with green background\n",
    "    with open('test_image.jpg', 'rb') as f:\n",
    "        files = {'image': f}\n",
    "        data = {'bg_color': '#00ff00'}  # Green background\n",
    "        \n",
    "        print(\"ðŸ“¤ Sending request to /remove-bg...\")\n",
    "        response = requests.post(\n",
    "            \"http://localhost:5000/remove-bg\", \n",
    "            files=files, \n",
    "            data=data,\n",
    "            timeout=60  # Give it time for model loading\n",
    "        )\n",
    "    \n",
    "    if response.status_code == 200:\n",
    "        result = response.json()\n",
    "        if result.get('success'):\n",
    "            print(\"âœ… Background removal successful!\")\n",
    "            \n",
    "            # Decode and display the result\n",
    "            image_data = base64.b64decode(result['image'])\n",
    "            result_image = Image.open(BytesIO(image_data))\n",
    "            \n",
    "            # Display original and processed images side by side\n",
    "            fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 6))\n",
    "            \n",
    "            ax1.imshow(image)\n",
    "            ax1.set_title(\"Original Image\")\n",
    "            ax1.axis('off')\n",
    "            \n",
    "            ax2.imshow(result_image)\n",
    "            ax2.set_title(\"Background Removed (Green BG)\")\n",
    "            ax2.axis('off')\n",
    "            \n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "            \n",
    "            print(\"ðŸŽ‰ Background removal test completed successfully!\")\n",
    "            print(\"ðŸ’¡ You can now use the public ngrok URL to access the API from anywhere!\")\n",
    "        else:\n",
    "            print(f\"âŒ API returned error: {result}\")\n",
    "    else:\n",
    "        print(f\"âŒ Request failed with status {response.status_code}\")\n",
    "        print(f\"Response: {response.text[:500]}\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"âŒ Test failed: {e}\")\n",
    "    print(\"ðŸ’¡ This is normal if models are still loading. Try running this cell again in a minute.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## ðŸ“ Step 7: Get Your Public URL & API Usage\n",
    "\n",
    "Your AutoRender AI service is now running! ðŸŽ‰"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the ngrok public URL\n",
    "try:\n",
    "    from pyngrok import ngrok\n",
    "    tunnels = ngrok.get_tunnels()\n",
    "    if tunnels:\n",
    "        public_url = tunnels[0].public_url\n",
    "        print(f\"ðŸŒ Your PUBLIC AutoRender AI URL: {public_url}\")\n",
    "        print(\"=\" * 60)\n",
    "        print()\n",
    "        print(\"ðŸ“‹ Available API Endpoints:\")\n",
    "        print(f\"   â€¢ {public_url}/health - Health check\")\n",
    "        print(f\"   â€¢ {public_url}/status - Service status & model info\")\n",
    "        print(f\"   â€¢ {public_url}/remove-bg - Background removal\")\n",
    "        print()\n",
    "        print(\"ðŸ’¡ Usage Examples:\")\n",
    "        print(f\"\"\"\n",
    "ðŸ”¹ Test with curl:\n",
    "   curl -X POST -F 'image=@your_image.jpg' {public_url}/remove-bg\n",
    "\n",
    "ðŸ”¹ With background color:\n",
    "   curl -X POST -F 'image=@your_image.jpg' -F 'bg_color=#ff0000' {public_url}/remove-bg\n",
    "\n",
    "ðŸ”¹ With edge blur:\n",
    "   curl -X POST -F 'image=@your_image.jpg' -F 'edge_blur_radius=2' {public_url}/remove-bg\n",
    "\n",
    "ðŸ”¹ Test from Python:\n",
    "   import requests\n",
    "   with open('image.jpg', 'rb') as f:\n",
    "       response = requests.post('{public_url}/remove-bg', \n",
    "                               files={{'image': f}},\n",
    "                               data={{'bg_color': '#ffffff'}})\n",
    "   result = response.json()\n",
    "        \"\"\")\n",
    "        \n",
    "        print(\"\\nðŸ” Save this URL - it will work until you stop this notebook!\")\n",
    "        \n",
    "    else:\n",
    "        print(\"âš ï¸  No ngrok tunnels found.\")\n",
    "        print(\"ðŸŒ Service is running locally on: http://localhost:5000\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(\"â„¹ï¸  Could not retrieve ngrok URL\")\n",
    "    print(\"ðŸŒ Service is running locally on: http://localhost:5000\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"ðŸŽ‰ AutoRender AI is ready to use!\")\n",
    "print(\"ðŸ”¥ The server will keep running until you stop this notebook.\")\n",
    "print(\"ðŸ“± You can test it from any device using the public URL above.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## ðŸ”§ Troubleshooting\n",
    "\n",
    "If you encounter any issues:\n",
    "\n",
    "1. **Models loading slowly**: This is normal on first run. Wait 2-3 minutes.\n",
    "2. **GPU not detected**: Go to `Runtime > Change runtime type > Hardware accelerator > GPU`\n",
    "3. **Ngrok errors**: The free version has limitations. Try restarting the notebook.\n",
    "4. **API errors**: Check the server logs above for detailed error messages.\n",
    "\n",
    "## ðŸŽ¯ Next Steps\n",
    "\n",
    "- Upload your own images to test\n",
    "- Try different background colors\n",
    "- Integrate with your applications\n",
    "- Check the [GitHub repository](https://github.com/BalajiAIDev/autorender-ai.git) for more features\n",
    "\n",
    "**Happy AI processing! ðŸš€**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.x"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
